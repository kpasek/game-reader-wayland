import cv2
import pytesseract
import numpy as np
import subprocess
from rapidfuzz import fuzz, process

# âš™ï¸ konfiguracja
TARGET_REGION = (100, 800, 900, 200)  # x, y, width, height
DIALOG_FILE = "subtitles.txt"
AUDIO_DIR = "audio/"
THRESHOLD = 85  # dopasowanie procentowe
CAPTURE_INTERVAL = 0.5

# ðŸ”Š komenda do odtwarzania audio
def play_audio(name):
    subprocess.Popen(["ffplay", "-nodisp", "-autoexit", f"{AUDIO_DIR}/{name}.ogg"],
                     stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)

# ðŸ“„ wczytanie dialogÃ³w
with open(DIALOG_FILE, "r", encoding="utf-8") as f:
    dialogs = [line.strip() for line in f if line.strip()]

# ðŸŽ¥ GStreamer â€” PipeWire capture (z portalu)
cap = cv2.VideoCapture("pipewiresrc ! videoconvert ! appsink", cv2.CAP_GSTREAMER)

if not cap.isOpened():
    raise RuntimeError("âŒ Nie udaÅ‚o siÄ™ otworzyÄ‡ PipeWire streamu")

print("âœ… Stream uruchomiony, trwa OCR...")

last_match = None
while True:
    ret, frame = cap.read()
    if not ret:
        continue

    # ðŸ“ przyciÄ™cie fragmentu
    x, y, w, h = TARGET_REGION
    roi = frame[y:y+h, x:x+w]

    # ðŸ”¤ OCR
    text = pytesseract.image_to_string(roi, lang="pol").strip()
    if not text:
        continue

    # ðŸ§  dopasowanie do dialogÃ³w
    match, score, _ = process.extractOne(text, dialogs, scorer=fuzz.token_set_ratio)
    if score >= THRESHOLD and match != last_match:
        print(f"ðŸŸ¢ Dopasowano: {match} ({score}%)")
        # play_audio(match)
        last_match = match
